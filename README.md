# ğŸ¤– Agente Inteligente RAG com FastAPI e Gemini

Um sistema avanÃ§ado de perguntas e respostas implementando arquitetura RAG (Retrieval Augmented Generation) com FastAPI, utilizando o modelo Gemini da Google para geraÃ§Ã£o de respostas contextualizadas.

## ğŸ“Œ VisÃ£o Geral

![RAG Architecture](![image](https://github.com/user-attachments/assets/8b6b5328-0bd6-4660-aa0d-14b7c628af11)
*(Diagrama conceitual da arquitetura RAG)*

O sistema combina:
- RecuperaÃ§Ã£o de informaÃ§Ã£o vetorial
- GeraÃ§Ã£o contextualizada de respostas
- Gerenciamento de conversaÃ§Ã£o

## ğŸš€ Funcionalidades Principais

| Funcionalidade | DescriÃ§Ã£o |
|--------------|-----------|
| ğŸ“„ Respostas baseadas em documentos | Consulta a base de conhecimento vetorial antes de gerar respostas |
| ğŸ—£ï¸ Contexto de conversa | MantÃ©m histÃ³rico da sessÃ£o para respostas contextualizadas |
| ğŸ”¢ Gerenciamento de tokens | Monitora uso de tokens para controle de custos |
| â±ï¸ Timeout inteligente | PrevenÃ§Ã£o de longas esperas em consultas complexas |
| ğŸŒ Suporte CORS | ConfiguraÃ§Ã£o flexÃ­vel para integraÃ§Ã£o frontend |

## ğŸ› ï¸ Stack TecnolÃ³gica

- **Backend**:
  - `FastAPI` (Framework web moderno)
  - `Uvicorn` (ASGI server)
- **IA/ML**:
  - `Google Gemini` (LLM avanÃ§ado)
  - `LangChain` (OrquestraÃ§Ã£o de fluxos LLM)
- **Banco de Dados Vetorial**:
  - `FAISS` (Facebook AI Similarity Search)
- **Embeddings**:
  - `HuggingFace` (Modelos de embeddings)

## âš™ï¸ ConfiguraÃ§Ã£o

### PrÃ©-requisitos
- Python 3.9+
- Conta no Google AI Studio (para chave API Gemini)

### InstalaÃ§Ã£o
```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Ou manualmente:
pip install fastapi uvicorn langchain google-generativeai faiss-cpu python-dotenv
```

### VariÃ¡veis de Ambiente
Crie um arquivo `.env` na raiz do projeto:
```ini
GEMINI_API_KEY=sua_chave_aqui
MAX_TOKENS=1000
TIMEOUT=30
```

## ğŸšï¸ Uso da API

### Endpoints DisponÃ­veis
| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| POST | /generate | Processa consultas e retorna respostas |
| GET | /health | Verifica status do serviÃ§o |


![image](https://github.com/user-attachments/assets/b8c272f4-dac6-4ff0-a25c-911ef879ac35)


### Exemplo de RequisiÃ§Ã£o
```python
import requests

url = "http://localhost:8000/generate"
payload = {
    "query": "Explique o conceito de RAG",
    "chat_history": [] # Opcional
}

response = requests.post(url, json=payload)
print(response.json())
```

### Estrutura da Resposta
```json
{
  "response": "Resposta gerada pelo modelo Gemini",
  "metadata": {
    "token_count": 215,
    "processing_time": 1.45,
    "sources": ["doc1.pdf", "doc2.txt"]
  },
  "chat_history": [...]
}
```

